{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab9607b-f3d9-4429-8f39-b325fd5b6249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipympl\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fitting as fit\n",
    "import data_utils as dat\n",
    "import vis\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb24286-4d7a-4e76-9b68-8f1e8e65cf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "mcode = \"410m-dense\"\n",
    "msize = mcode.split(\"-\")[0]\n",
    "tasks = [\"github\", \"stackexchange\", \"arxiv\", \"pile-cc\"]  # and full?\n",
    "df_llc, df_loss = dat.load_dfs(mcode, data_path=\"data\")\n",
    "step_start = 2000  # are we cropping too early?\n",
    "step_end = 80000\n",
    "step_cutoff = 20000\n",
    "scale = 1000.  # rescale steps for the time-fits only\n",
    "\n",
    "colors = vis.assign_cols(df_llc.columns)\n",
    "\n",
    "# Tweak so stuff fits...\n",
    "fwidth = 1300\n",
    "fheight= 450\n",
    "\n",
    "\n",
    "WRITE = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6191dd8-605a-41a3-aa32-72bdb425c9d8",
   "metadata": {},
   "source": [
    "# Parametric loss over time\n",
    "Perhaps we should be using RMSE for everything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fef71e-5173-4c99-907b-ae56b7b2cd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate functions:\n",
    "functions = [\n",
    "    (fit.OffsetPowerLaw2, {}, \"Powerlaw\"),\n",
    "    (fit.OffsetExponential, dict(par0=[1., 1., -.1]), \"Exponential\"),\n",
    "]\n",
    "\n",
    " # Make a grid layout\n",
    "titles = []\n",
    "for f in functions:\n",
    "    for s in [\"Fit\", \"Holdout\"]:\n",
    "        titles.append(f\"{f[2]} - {s}\")\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=len(functions), cols=2,\n",
    "    subplot_titles=titles,\n",
    "    horizontal_spacing=0.1,\n",
    "    vertical_spacing=0.1,\n",
    ")\n",
    "\n",
    "fnames = [f[2] for f in functions]\n",
    "loss_fits = {f: {} for f in fnames}\n",
    "loss_vals = {f: {} for f in fnames}\n",
    "\n",
    "for task in tasks:\n",
    "    llc, loss, steps = dat.trim_trace(df_llc, df_loss, task, step_start, step_end)\n",
    "    trace = dat.Trace(steps/scale, loss, steps)  # loss vs step\n",
    "    train, test = dat.split(trace, step_cutoff)\n",
    "    color = colors[task]\n",
    "    color2 = vis.add_color(color)  # for heldout data\n",
    "    \n",
    "    \n",
    "    for f_ind, (function, args, fname) in enumerate(functions):\n",
    "                \n",
    "        # Fit full and validation results\n",
    "        loss_fits[fname][task] = result = fit.min_fit(trace.x, trace.y, function, **args)\n",
    "        loss_vals[fname][task] = v_result = fit.min_fit(train.x, train.y, function, **args)\n",
    "        \n",
    "        # Evaluate the metrics\n",
    "        y_fit = result.f(trace.x)\n",
    "        RMSE_fit = fit.rmse(trace.y, y_fit)\n",
    "        y_val = v_result.f(test.x)\n",
    "        RMSE_val = fit.rmse(test.y, y_val)\n",
    "        description = f\"{task}<br>RMSE={RMSE_fit:.4f} (fit),<br>RMSE={RMSE_val:.4f} (holdout)\"\n",
    "\n",
    "        # Left column: plot the fit\n",
    "        subplot = dict(row=f_ind+1, col=1)\n",
    "        vis.plot_data(fig, trace.x, trace.y, color=color, showlegend=False, size=5, xscale=scale, subplot=subplot) \n",
    "        vis.plot_result(fig, trace.x, result, name=description, xscale=scale, color=color, subplot=subplot,\n",
    "                        showlegend=True, legendgroup=fname)\n",
    "        fig.update_xaxes(title_text=\"Step\", type=\"log\", **subplot)\n",
    "        fig.update_yaxes(title_text=r\"$\\text{Loss }L$\", **subplot)\n",
    "\n",
    "        # Right column: plot the validation\n",
    "        subplot = dict(row=f_ind+1, col=2)\n",
    "        vis.plot_data(fig, train.x, train.y, color=color, showlegend=False, size=5, xscale=scale, subplot=subplot) \n",
    "        vis.plot_data(fig, test.x, test.y, color=color2, showlegend=False, size=5, xscale=scale, subplot=subplot) \n",
    "        vis.plot_result(fig, trace.x, v_result, name=task, xscale=scale, color=color, showlegend=False, subplot=subplot)\n",
    "        fig.update_xaxes(title_text=\"Step\", type=\"log\", **subplot)\n",
    "        fig.update_yaxes(title_text=r\"$\\text{Loss }L$\", **subplot)\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"\",\n",
    "    width=fwidth,\n",
    "    height=fheight * len(functions),\n",
    "    showlegend=True,\n",
    "    legend_tracegroupgap=250,  # annoying - have to eyeball this\n",
    ")\n",
    "\n",
    "if WRITE:\n",
    "    fname = f\"plots/parametric_loss_{msize}.pdf\"\n",
    "    fig.write_image(fname)  # yes we have to repeat to avoid \"loading mathjax\" in the bottom left\n",
    "    import time\n",
    "    print(\"Waiting\")\n",
    "    time.sleep(1)\n",
    "    fig.write_image(fname)\n",
    "    print(f\"Done. See {fname}\")\n",
    "\n",
    "fig.show()  # as soon as you include latex you loose the ability to see the labels in html\n",
    "\n",
    "# Let's just outright reject exponential - its not a candidate\n",
    "if \"Exponential\" in loss_fits:\n",
    "    del loss_fits[\"Exponential\"]\n",
    "    del loss_vals[\"Exponential\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb17f30-c6f4-450d-99e5-3e9fa1d24411",
   "metadata": {},
   "source": [
    "# Clear winner --> delete exponential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dd224b-5f64-4b2c-9ac4-3e7801422758",
   "metadata": {},
   "source": [
    "# Step 2: LLC vs time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d00ba6b-f334-4ce7-a668-3df4f025f060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically a cut'n'paste job\n",
    "\n",
    "# Candidate functions:\n",
    "functions = [\n",
    "    (fit.OffsetPowerLaw, dict(par0=[10., -10., .1]), \"Powerlaw\"),\n",
    "    (fit.OffsetLogarithm, {}, \"Logarithm\"),\n",
    "]\n",
    "\n",
    "# Make a grid layout\n",
    "titles = []\n",
    "for f in functions:\n",
    "    for s in [\"Fit\", \"Holdout\"]:\n",
    "        titles.append(f\"{f[2]} - {s}\")\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=len(functions), cols=2,\n",
    "    subplot_titles=titles,\n",
    "    horizontal_spacing=0.1,\n",
    "    vertical_spacing=0.1,\n",
    ")\n",
    "\n",
    "report = []\n",
    "fnames = [f[2] for f in functions]\n",
    "llc_fits = {f: {} for f in fnames}\n",
    "llc_vals = {f: {} for f in fnames}\n",
    "\n",
    "\n",
    "for task in tasks:\n",
    "    llc, loss, step = dat.trim_trace(df_llc, df_loss, task, step_start, step_end)\n",
    "    trace = dat.Trace(steps/scale, llc, steps)  # llc vs step\n",
    "    train, test = dat.split(trace, step_cutoff)\n",
    "    color = colors[task]\n",
    "    color2 = vis.add_color(color)  # for heldout data\n",
    "    \n",
    "    \n",
    "    for f_ind, (function, args, fname) in enumerate(functions):\n",
    "        # Save outputs for later use?\n",
    "        llc_fits[fname][task] = result = fit.min_fit(trace.x, trace.y, function, **args)\n",
    "        llc_vals[fname][task] = v_result = fit.min_fit(train.x, train.y, function, **args)\n",
    "        \n",
    "        # Evaluate the metrics\n",
    "        y_fit = result.f(trace.x)\n",
    "        RMSE_fit = fit.rmse(trace.y, y_fit)\n",
    "        y_val = v_result.f(test.x)\n",
    "        RMSE_val = fit.rmse(test.y, y_val)\n",
    "\n",
    "        print(function.name, task, result.params_dict)\n",
    "        \n",
    "        description = f\"{task}<br>RMSE={RMSE_fit:.4f} (fit),<br>RMSE={RMSE_val:.4f} (holdout)\"\n",
    "\n",
    "        # Left column: plot the fit\n",
    "        subplot = dict(row=f_ind+1, col=1)\n",
    "        vis.plot_data(fig, trace.x, trace.y, color=color, showlegend=False, size=5, xscale=scale, subplot=subplot) \n",
    "        vis.plot_result(fig, trace.x, result, name=description, xscale=scale, color=color, subplot=subplot,\n",
    "                        showlegend=True, legendgroup=fname)\n",
    "        fig.update_xaxes(title_text=\"Step\", type=\"log\", **subplot)\n",
    "        fig.update_yaxes(title_text=r\"$\\text{Estimated and transformed LLC }\\,\\frac{1}{100}\\hat{\\lambda}$\", **subplot)\n",
    "\n",
    "        # Right column: plot the validation\n",
    "        subplot = dict(row=f_ind+1, col=2)\n",
    "        vis.plot_data(fig, train.x, train.y, color=color, showlegend=False, size=5, xscale=scale, subplot=subplot) \n",
    "        vis.plot_data(fig, test.x, test.y, color=color2, showlegend=False, size=5, xscale=scale, subplot=subplot) \n",
    "        vis.plot_result(fig, trace.x, v_result, name=task, xscale=scale, color=color, showlegend=False, subplot=subplot)\n",
    "        fig.update_xaxes(title_text=\"Step\", type=\"log\", **subplot)\n",
    "        fig.update_yaxes(title_text=r\"$\\text{Estimated and transformed LLC }\\,\\frac{1}{100}\\hat{\\lambda}$\", **subplot)\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"\",\n",
    "    width=fwidth,\n",
    "    height=fheight* len(functions),\n",
    "    showlegend=True,\n",
    "    legend_tracegroupgap=250,  # annoying - have to eyeball this\n",
    ")\n",
    "\n",
    "if WRITE:\n",
    "    fname = f\"plots/parametric_llc_{msize}.pdf\"\n",
    "    fig.write_image(fname)\n",
    "    print(f\"Done. See {fname}\")\n",
    "\n",
    "    \n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66797bf-4a91-453b-bc4f-0ca33d3ca28c",
   "metadata": {},
   "source": [
    "# Step 3: LLC vs loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ba380-8094-4a95-8498-2fe460e81553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct-fit candidates:\n",
    "functions = [\n",
    "    #(fit.DoubleOffsetPowerLaw, {}, \"Powerlaw (4 param)\"),\n",
    "    #(fit.OffsetPowerLaw, {}, \"Direct Powerlaw (3 par)\"),\n",
    "    #(fit.OffsetExponential, {}, \"Exponential (3 param)\"),\n",
    "]\n",
    "for a in llc_fits:\n",
    "    for b in loss_fits:\n",
    "        functions.append(\n",
    "            (\"construct\", (a, b), f\"{a}-{b}\")\n",
    "        )\n",
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b7c802-b2d4-46fc-915a-c639a8a488f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Make a grid layout\n",
    "titles = []\n",
    "for f in functions:\n",
    "    for s in [\"Fit\", \"Holdout\"]:\n",
    "        titles.append(f\"{f[2]} - {s}\")\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=len(functions), cols=2,\n",
    "    subplot_titles=titles,\n",
    "    horizontal_spacing=0.1,\n",
    "    vertical_spacing=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "for task in tasks:\n",
    "    trace = dat.trim_trace(df_llc, df_loss, task, step_start, step_end)\n",
    "    train, test = dat.split(trace, step_cutoff)\n",
    "    color = colors[task]\n",
    "    color2 = vis.add_color(color)  # for heldout data    \n",
    "    \n",
    "    for f_ind, (function, args, fname) in enumerate(functions):\n",
    "\n",
    "        \n",
    "        if function == \"construct\":\n",
    "            # Rather than fitting loss vs llc\n",
    "            # We can mash the results together and make a \"result\" for it\n",
    "            \n",
    "            llc_result = llc_fits[args[0]][task]\n",
    "            loss_result = loss_fits[args[1]][task]\n",
    "            def mash(x):\n",
    "                # Compute the latent step\n",
    "                vstep = llc_result.model.inverse(x, llc_result.params)\n",
    "                return loss_result.f(vstep)\n",
    "            \n",
    "\n",
    "            llc_vresult = llc_vals[args[0]][task]\n",
    "            loss_vresult = loss_vals[args[1]][task]\n",
    "            def vmash(x):\n",
    "                # Compute the latent step\n",
    "                vstep = llc_vresult.model.inverse(x, llc_vresult.params)\n",
    "                return loss_vresult.f(vstep)\n",
    "            \n",
    "            result = fit.FitResult(mash, None, {}, None, None, None)\n",
    "            v_result = fit.FitResult(vmash, None, {}, None, None, None)\n",
    "            \n",
    "        else:\n",
    "            # Fit the trace from scratch\n",
    "            result = fit.min_fit(trace.x, trace.y, function, **args)\n",
    "            v_result = fit.min_fit(train.x, train.y, function, **args)\n",
    "        \n",
    "        # Evaluate the metrics\n",
    "        y_fit = result.f(trace.x)\n",
    "        RMSE_fit = fit.rmse(trace.y, y_fit)\n",
    "        y_val = v_result.f(test.x)\n",
    "        RMSE_val = fit.rmse(test.y, y_val)\n",
    "        description = f\"{task}<br>RMSE={RMSE_fit:.5f} (fit),<br>RMSE={RMSE_val:.5f} (holdout)\"\n",
    "\n",
    "        # Left column: plot the fit\n",
    "        subplot = dict(row=f_ind+1, col=1)\n",
    "        vis.plot_data(fig, trace.x, trace.y, color=color, showlegend=False, size=5, subplot=subplot) \n",
    "        vis.plot_result(fig, trace.x, result, name=description, color=color, subplot=subplot,\n",
    "                        showlegend=True, legendgroup=fname)\n",
    "        fig.update_yaxes(title_text=r\"$\\text{Loss }L$\", **subplot)\n",
    "        fig.update_xaxes(title_text=r\"$\\text{Estimated and transformed LLC }\\,\\frac{1}{100}\\hat{\\lambda}$\", **subplot)\n",
    "\n",
    "        # Right column: plot the validation\n",
    "        subplot = dict(row=f_ind+1, col=2)\n",
    "        vis.plot_data(fig, train.x, train.y, color=color, showlegend=False, size=5, subplot=subplot) \n",
    "        vis.plot_data(fig, test.x, test.y, color=color2, showlegend=False, size=5, subplot=subplot) \n",
    "        vis.plot_result(fig, trace.x, v_result, name=task, color=color, showlegend=False, subplot=subplot)\n",
    "        fig.update_yaxes(title_text=r\"$\\text{Loss }L$\", **subplot)\n",
    "        fig.update_xaxes(title_text=r\"$\\text{Estimated and transformed LLC }\\,\\frac{1}{100}\\hat{\\lambda}$\", **subplot)\n",
    "        \n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"\",\n",
    "    width=fwidth,\n",
    "    height=fheight* len(functions),\n",
    "    showlegend=True,\n",
    "    legend_tracegroupgap=260,  # annoying - have to eyeball this\n",
    ")\n",
    "\n",
    "if WRITE:\n",
    "    fname = f\"plots/parametric_trajectory_{msize}.pdf\"\n",
    "    fig.write_image(fname)\n",
    "    print(f\"Done. See {fname}\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c141393-281f-41ed-b7fc-d195aa2d051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure experiment\n",
    "fit_method = fit.min_fit  # odr_fit is also an option\n",
    "function = fit.OffsetPowerLaw\n",
    "mcode = '410m-dense'\n",
    "step_start = 2000  # As long as it is consistent\n",
    "step_end = 80000\n",
    "step_cutoff = 20000  # TODO: investigate if this point is in the train or the test set\n",
    "df_llc, df_loss = dat.load_dfs(mcode, data_path=\"data\")\n",
    "trace = dat.trim_trace(df_llc, df_loss, \"github\", step_start, step_end)\n",
    "train, test = dat.split(trace, step_cutoff)\n",
    "\n",
    "# using the oracle parameters as an initalisation is not *technially cheating but it does seem to make a difference\n",
    "#oracle = fit_method(trace.x, trace.y, function)\n",
    "#result = fit_method(train.x, train.y, function, par0=oracle.params)\n",
    "\n",
    "result = fit_method(train.x, train.y, function)\n",
    "\n",
    "y_pred = result.f(test.x)\n",
    "rmse = fit.rmse(test.y, y_pred)\n",
    "rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fc2de4-fcfa-4326-8a06-ad57de8d3695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
