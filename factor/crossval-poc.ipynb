{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9091a6-810e-4d20-a327-e17a00b5cf88",
   "metadata": {},
   "source": [
    "# Crossval-POC\n",
    "\n",
    "We can't do *pure* crossval with entire rows because when we fit the new row to the model we're observing the data in a way.\n",
    "But we can probably still do model selection by when the improvement in fit diverges from the improvement in crossval.\n",
    "\n",
    "There's also an example [here](https://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_vs_fa_model_selection.html#sphx-glr-auto-examples-decomposition-plot-pca-vs-fa-model-selection-py) I'm interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf353a9-c3ec-4042-a8b4-a9e871e54f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd74d03-c52d-44bc-8977-b176464f40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Local files\n",
    "import factor\n",
    "import selection\n",
    "import vis\n",
    "import data\n",
    "\n",
    "# Load models\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4144f70e-3e62-485e-ab1c-e6c514d00a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.load(\"helm\")  # helm, p70m or synthetic\n",
    "\n",
    "# Or perhaps there are small predictive features that are getting clobbered by large spurious features\n",
    "# (poor signal to noise ratio)\n",
    "\n",
    "print(f\"{X.shape[0]} models, {X.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a00222-4977-4599-ad47-91f4cce71eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do row-wise cross validation for model selection\n",
    "\n",
    "Z = StandardScaler().fit_transform(X)\n",
    "\n",
    "n_components = np.arange(1, 12)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "indices = np.arange(X.shape[0])\n",
    "\n",
    "\n",
    "# scores = cross_val_score(LogisticRegression(), X, y, cv=5, scoring='f1')\n",
    "#  for regressors, default is negative MSE (so higher is better?)\n",
    "\n",
    "RMSEs = []\n",
    "FULLs = []\n",
    "for n in n_components:\n",
    "    \n",
    "    pca = PCA(n_components=n)\n",
    "    mse = []\n",
    "\n",
    "    Q = pca.fit_transform(Z)\n",
    "    R = pca.inverse_transform(Q)\n",
    "    _score = ((Z-R)**2).ravel().mean() ** .5\n",
    "    FULLs.append(_score)\n",
    "\n",
    "    # The default scorer is log likelihood under probablistic PCA.. hmm\n",
    "    # Not the reconstruction score (I'm thinking of this like a regression)\n",
    "    #cv = (-cross_val_score(pca, X).mean(axis=0)) ** .5\n",
    "    # RMSEs.append(cv)\n",
    "    scores = []\n",
    "    for train_ix, test_ix in kf.split(indices):\n",
    "        # get HOLDOUT error here\n",
    "        Q = pca.fit_transform(Z[train_ix])\n",
    "        target = Z[test_ix]\n",
    "        S = pca.transform(target)\n",
    "        R = pca.inverse_transform(S)\n",
    "        _score = ((target-R)**2).ravel().mean() ** .5\n",
    "        scores.append(_score)\n",
    "    RMSEs.append(np.mean(scores))\n",
    "\n",
    "al_MSEs, al_std, fit_err = selection.cross_validate(Z, factor.PCA(), n_components[-1], n_folds=10, repeats=2)\n",
    "al_MSEs = al_MSEs ** .5\n",
    "fit_err = np.array(fit_err) ** .5\n",
    "\n",
    "\n",
    "plt.figure\n",
    "plt.plot(n_components, RMSEs, label=\"Row holdout (scikit-learn)\")\n",
    "plt.plot(n_components, FULLs, label=\"No holdout (scikit-learn)\")\n",
    "plt.plot(n_components, al_MSEs, label=\"Partial holdout (inhouse)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7959cdb-4cb6-48b8-9b91-3f180c88a827",
   "metadata": {},
   "source": [
    "# Thoughts:\n",
    "* You can see the elbow in all (even non-holdout) - so we'd *probably* guess the right dimensions\n",
    "* Only my holdout method definitively shows overfitting\n",
    "* I believe some methods respond better to row holdout, eg factor analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
