{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9091a6-810e-4d20-a327-e17a00b5cf88",
   "metadata": {},
   "source": [
    "# Crossval-POC\n",
    "\n",
    "We can't do *pure* crossval with entire rows because when we fit the new row to the model we're observing the data in a way.\n",
    "But we can probably still do model selection by when the improvement in fit diverges from the improvement in crossval.\n",
    "\n",
    "There's also an example [here](https://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_vs_fa_model_selection.html#sphx-glr-auto-examples-decomposition-plot-pca-vs-fa-model-selection-py) I'm interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf353a9-c3ec-4042-a8b4-a9e871e54f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd74d03-c52d-44bc-8977-b176464f40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Local files\n",
    "import factor\n",
    "import selection\n",
    "import vis\n",
    "import data\n",
    "\n",
    "# Load models\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4144f70e-3e62-485e-ab1c-e6c514d00a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.load(\"p70m\")  # helm, p70m or synthetic\n",
    "\n",
    "# Or perhaps there are small predictive features that are getting clobbered by large spurious features\n",
    "# (poor signal to noise ratio)\n",
    "\n",
    "print(f\"{X.shape[0]} models, {X.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a00222-4977-4599-ad47-91f4cce71eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do row-wise cross validation for model selection\n",
    "\n",
    "Z = StandardScaler().fit_transform(X)\n",
    "n_components = 10\n",
    "row_MSEs, row_std, row_fit = selection.row_cross_validate(Z, PCA(), n_components)\n",
    "al_MSEs, al_std, fit_err = selection.cross_validate(Z, factor.PCA(), n_components)\n",
    "\n",
    "components = np.arange(n_components) + 1\n",
    "plt.figure\n",
    "plt.plot(components, row_MSEs, label=\"Row holdout (scikit-learn)\")\n",
    "plt.plot(components, fit_err, label=\"No holdout (scikit-learn)\")\n",
    "plt.plot(components, al_MSEs, label=\"Partial holdout (inhouse)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7959cdb-4cb6-48b8-9b91-3f180c88a827",
   "metadata": {},
   "source": [
    "# Thoughts:\n",
    "* You can see the elbow in all (even non-holdout) - so we'd *probably* guess the right dimensions\n",
    "* Only my holdout method definitively shows overfitting\n",
    "* I believe some methods respond better to row holdout, eg factor analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
