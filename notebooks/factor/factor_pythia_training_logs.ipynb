{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f83da51d-aa07-4dd3-b19b-44e656e1f72a",
   "metadata": {},
   "source": [
    "# Factor Analysis on Pythia training logs\n",
    "\n",
    "Eleuther ran some evals during training that are available in their pythia repo.\n",
    "Here we load and factorise that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdbaac3-6e8a-4ccf-b590-706278eae402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from lsoc.factor import factor, selection, vis, data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7f177a-aed1-4e39-94cf-4bc93ecab3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsoc.factor import data\n",
    "\n",
    "models = [\n",
    "    \"pythia-70m\",\n",
    "    \"pythia-160m\",\n",
    "    \"pythia-410m\",\n",
    "    \"pythia-1.4b\",\n",
    "    \"pythia-2.8b\",\n",
    "    \"pythia-6.9b\",\n",
    "    \"pythia-12b\",\n",
    "]\n",
    "output_path = data.default_path + \"/evals/eleuther\"\n",
    "\n",
    "model_dfs = {}\n",
    "for model in models:\n",
    "    print(model)\n",
    "    path = f\"{output_path}/{model}.csv\"\n",
    "    model_dfs[model] = pd.read_csv(path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf83ede-fd76-431d-a641-deba1a239e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the final checkpoint (it's going to be at most 7-dimensional, but I bet it's lower)\n",
    "final = 143000\n",
    "extract = {}\n",
    "for model in models:\n",
    "    extract[model] = model_dfs[model].loc[final]\n",
    "\n",
    "    #row_means = model_dfs[model].mean(axis=1)\n",
    "    # Find the index of the row with the highest average value\n",
    "    # max_mean_idx = row_means.idxmax()\n",
    "    # Extract the row with the highest average value\n",
    "    #extract[model] = model_dfs[model].loc[max_mean_idx]\n",
    "\n",
    "mini_psych = pd.DataFrame(extract).T\n",
    "print(\"Psychometrics Matrix (EOT)\")\n",
    "mini_psych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf4d3cb-dcfa-4c1b-bad6-3be24e4a64ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Its strongly one-dimensional - I guess that makes sense because that factor is model-size\n",
    "\n",
    "#scaled = StandardScaler().fit_transform(mini_psych)\n",
    "scaled = mini_psych\n",
    "model = factor.PCA(iters=50)  # inhouse leaveout recipe\n",
    "# model = factor.FA(iters=20)  # look, they generally agree!\n",
    "errs = selection.cross_validate(scaled, model, max_factors=3, n_folds=10, repeats=1)\n",
    "fig = vis.crossval(*errs, method_name=model.name)\n",
    "# Improve layout\n",
    "fig.update_layout(\n",
    "    xaxis_title='Number of factors',\n",
    "    yaxis_title='Reconstruction Error',\n",
    "    showlegend=True\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f287f98-1e47-4c75-8c82-45036925713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try what do the factor analysis factors look like?\n",
    "\n",
    "factr = FactorAnalysis(1)\n",
    "factr.fit(mini_psych)\n",
    "\n",
    "# Create a figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add a trace for each model\n",
    "for model in models:\n",
    "    Xp = model_dfs[model]\n",
    "    yp = -factr.transform(Xp)[:,0]\n",
    "    st = Xp.index\n",
    "    # Add trace with model name annotation\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=st,\n",
    "            y=yp,\n",
    "            mode='lines+markers',\n",
    "            name=model,\n",
    "            hovertemplate= model + '<br>Step: %{x}<br>Effective Size: %{y:.1e}'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update layout with proper labels and log scales\n",
    "fig.update_layout(\n",
    "    title='Factor Analysis (1 factor final checkpoint)',\n",
    "    xaxis_title='Step',\n",
    "    yaxis_title='Latent Factor',\n",
    "    xaxis_type='log',  # Set x-axis to log scale\n",
    "    # yaxis_type='log',  # Set y-axis to log scale\n",
    "    legend_title='Models',\n",
    "    hovermode='closest',\n",
    "    template='plotly_white',\n",
    "    width=900,\n",
    "    height=600,\n",
    "    margin=dict(l=80, r=80, t=100, b=80)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b849f4cf-9779-47a6-b521-280f14b671e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which components have the highest loading?\n",
    "components = np.abs(factr.components_[0])\n",
    "keep = components > 1e-8\n",
    "\n",
    "w = pd.DataFrame(\n",
    "    [components[keep]],\n",
    "    columns=mini_psych.columns.values[keep],\n",
    ")\n",
    "w.T.sort_values(by=0, ascending=False).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909ffac3-ec57-4fdb-b66c-8c47c276b4fa",
   "metadata": {},
   "source": [
    "Copyright (c) Gradient Institute and Timaeus. All rights reserved.\n",
    "\n",
    "Licensed under the Apache 2.0 License.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
