{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a55278c7-019e-4dd4-91ca-b5315f03b816",
   "metadata": {},
   "source": [
    "# Process Diverse(TM) Models\n",
    "\n",
    "We've gone and run a lot of publicly available models on our [timaeus/pile-subsets-mini](https://huggingface.co/datasets/timaeus/pile_subsets_mini).\n",
    "\n",
    "To help establish the link between fine grained pile-subset-losses and eval scores, we're looking at the structure of the latent factors \n",
    "Or latent factors thereof....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b20908-c203-45a7-acd6-a90b38dd0424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import lsoc\n",
    "from lsoc.factor import factor, selection, vis, data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.graph_objects as go  # temporarily don't drop\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from lsoc.powerlaw.vis import assign_cols\n",
    "# Get the path to the output directory\n",
    "SAVE = False\n",
    "save_path = \"plots\"\n",
    "\n",
    "if SAVE:\n",
    "    os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f77d4d-e609-4805-a16a-06f913eb4fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f\"{data.default_path}/evals/psych-20.csv\"\n",
    "psych = pd.read_csv(fname, index_col=0)\n",
    "psych.drop(index=\"Gemma_Instruct_(7B)\", inplace=True)\n",
    "assert psych.isna().sum().sum() == 0\n",
    "psych.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e75f61-944d-4bc9-86e0-d8c3e716c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "scaler = factor.ConstScaler(100.)\n",
    "\n",
    "X = pd.DataFrame(\n",
    "    scaler.fit_transform(psych),\n",
    "    columns=psych.columns,\n",
    "    index=psych.index,\n",
    ")\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3cca12-155c-4c3c-ab8e-85a68034536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate number of dimensions\n",
    "model = factor.FA()  # or PCA\n",
    "errs = selection.cross_validate(X, model, max_factors=7, n_folds=5, repeats=5)\n",
    "fig = vis.crossval(*errs, method_name=model.name)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb3cadf-31b8-4fa6-b821-0b3cdc984cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    fig.write_image(f\"{save_path}/FA_crossval.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1d89f2-75b1-4672-b2fa-d148a09f7fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from factor_analyzer import FactorAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b674c97-f988-4ab0-a36b-5626e1cd9616",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 4\n",
    "\n",
    "# Both oblimin and varimax try to make the loadings sparse\n",
    "# oblimin is oblique, allowing it to be *more sparse by having non-orthogonal scores\n",
    "fa_final, fa_name = FactorAnalyzer(rotation='oblimin', n_factors=n_components), \"FactorAnalyzer\"  \n",
    "\n",
    "def get_scores(X, fa):\n",
    "    H = fa.loadings_\n",
    "    X_scaled = (X - fa_final.mean_) / fa_final.std_\n",
    "    return X_scaled @ H @ np.linalg.pinv(H.T @ H)\n",
    "\n",
    "fa_final.fit(X)\n",
    "\n",
    "scores = get_scores(X, fa_final)\n",
    "\n",
    "if hasattr(fa_final, \"components_\"):\n",
    "    print(\"using scikit components\")\n",
    "    loadings = fa_final.components_.T\n",
    "else:\n",
    "    print(\"using factoranalyzer components\")\n",
    "    loadings = fa_final.loadings_\n",
    "    \n",
    "component_names = [f\"PC{i+1}\" for i in range(n_components)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19d6bcd-b12a-4f16-9209-dbd17f27272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_loadings = True\n",
    "\n",
    "# This code takes the loadings, makes a df H and plots it\n",
    "H = loadings\n",
    "\n",
    "if scale_loadings:\n",
    "    H = H / np.abs(H).max(axis=0)\n",
    "    extra = \" (scaled range)\"\n",
    "else:\n",
    "    extra = \"\"\n",
    "\n",
    "H = pd.DataFrame(\n",
    "    data=H,\n",
    "    index=X.columns,\n",
    "    columns=component_names,\n",
    ")\n",
    "\n",
    "fig = vis.heatmap(\n",
    "    H,\n",
    "    title=f\"Task Loadings ({fa_name}){extra}\",\n",
    "    width=6,\n",
    "    height=64,\n",
    "    reversescale=True\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ff774-7295-4fc9-ad33-c719dd088790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate even further to subsets!\n",
    "I = H.copy()\n",
    "I['source'] = [s.split()[0] for s in H.index]\n",
    "grouped_means = I.groupby('source').mean().T\n",
    "grouped_means.round(3).to_dict(orient='list')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715f4d2c-fe36-449f-a1e8-f9e4d19d727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Loadings are so tall that to put them in a report we should save them in parts:\n",
    "if SAVE:\n",
    "    fig1 = vis.heatmap(\n",
    "        H[:80],\n",
    "        title=f\"Task Loadings ({fa_name}){extra}\",\n",
    "        width=6,\n",
    "        height=32,\n",
    "        reversescale=True,\n",
    "        zmin=-1.,\n",
    "        zmax=1.,\n",
    "        showscale=False,\n",
    "    )\n",
    "    fig2 = vis.heatmap(\n",
    "        H[80:160],\n",
    "        title=f\"Task Loadings ({fa_name}){extra}\",\n",
    "        width=6,\n",
    "        height=32,\n",
    "        reversescale=True,\n",
    "        zmin=-1.,\n",
    "        zmax=1.,\n",
    "        showscale=False,\n",
    "    )\n",
    "    fig3 = vis.heatmap(\n",
    "        H[160:],\n",
    "        title=f\"Task Loadings ({fa_name}){extra}\",\n",
    "        width=6,\n",
    "        height=24,\n",
    "        reversescale=True,\n",
    "        zmin=-1.,\n",
    "        zmax=1.,\n",
    "        showscale=True,\n",
    "    )\n",
    "\n",
    "    \n",
    "    fig1.write_image(f\"{save_path}/loadings-a.png\", scale=2)\n",
    "    fig2.write_image(f\"{save_path}/loadings-b.png\", scale=2)\n",
    "    fig3.write_image(f\"{save_path}/loadings-c.png\", scale=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47329a72-d488-4786-8af4-390d909d2438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now display the model scores\n",
    "scale_scores = True\n",
    "# This code takes the loadings, makes a df W and plots it\n",
    "\n",
    "W = -get_scores(X, fa_final).values  # Higher losses are worse (unlike accuracy)\n",
    "\n",
    "if scale_scores:\n",
    "    W = W / np.abs(W).max(axis=0)\n",
    "    extra = \" (scaled range)\"\n",
    "else:\n",
    "    W = W + 0  # copy\n",
    "    extra = \"\"\n",
    "\n",
    "# Convert to dataframe\n",
    "W = pd.DataFrame(\n",
    "    data=W,\n",
    "    index=X.index,\n",
    "    columns=component_names,\n",
    ")\n",
    "\n",
    "# Sort by model name\n",
    "W = W.sort_index(ascending=True)\n",
    "\n",
    "fig = vis.heatmap(\n",
    "    W, # positive loss is bad though?\n",
    "    title=f\"Scores ({fa_name}){extra}\",\n",
    "    width=8,\n",
    "    height=12,\n",
    "    reversescale=True\n",
    ")\n",
    "\n",
    "if SAVE:\n",
    "    fig.write_image(f\"{save_path}/scores.png\", scale=2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db014a8f-b514-4fb6-835f-ead2a6b9c2e6",
   "metadata": {},
   "source": [
    "# Project Pythia Scores onto these factors\n",
    "\n",
    "# Losses look a bit big for untrained models, but mostly... fine?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4a7d23-ec61-44d0-8488-48c37b886138",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f\"{data.default_path}/evals/pythia-psych-20.csv\"\n",
    "pythia = pd.read_csv(fname, index_col=0)\n",
    "p_scaled = scaler.transform(pythia)\n",
    "p_scaled.loc[\"Pythia_70m_143000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f183c3c-b3bc-4c17-9950-f02ae096e01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[\"Pythia_(70m)\"]  # YAY!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56620b19-2d61-4d0d-94d7-83d13be7e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "W.loc[\"Pythia_(70m)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9734c46b-22e1-42e5-b9d5-bfd7bef6835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Solves for W in the equation X = WH\"\"\"\n",
    "ref_scores = get_scores(X, fa_final)\n",
    "p_scores = get_scores(p_scaled, fa_final)\n",
    "# _mu = ref_scores.mean(axis=0)\n",
    "# _std = ref_scores.std(axis=0)\n",
    "# r_scores = -(p_scores - _mu)/_std\n",
    "# ref_scores = -(ref_scores - _mu)/_std\n",
    "\n",
    "ma = ref_scores.abs().max(axis=0)\n",
    "r_scores = -p_scores / ma\n",
    "ref_scores = -ref_scores / ma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8835eb-a95d-47a0-b816-a9d2ba89d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f944f99b-dbaa-48cd-a156-65f75cdf55dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the aggregated pythia features\n",
    "pythia = [\"70m\", \"160m\", \"410m\", \"1b\", \"1.4b\", \"2.8b\", \"6.9b\"]  # \"14m\", \"31m\", \n",
    "available = p_scores.index.values\n",
    "colors = assign_cols(list(pythia) + [\"yellow\"] , 'viridis')\n",
    "compares = ref_scores.idxmax()  #list(set(ref_scores.idxmax()) | set(ref_scores.idxmin()))\n",
    "ccols = assign_cols(compares, 'jet')\n",
    "ymin = -1\n",
    "# Create the figure with 4 stacked rows\n",
    "fig = make_subplots(rows=n_components, cols=1, shared_xaxes=True, \n",
    "                    vertical_spacing=0.05, \n",
    "                    subplot_titles=component_names)\n",
    "\n",
    "\n",
    "cutoff = 512\n",
    "\n",
    "\n",
    "for size in pythia:\n",
    "    \n",
    "    inds = [a for a in available if size in a]\n",
    "    if len(inds) == 0:\n",
    "        continue\n",
    "    steps = [int(v.split(\"_\")[-1]) for v in inds]\n",
    "    steps, inds = zip(*sorted(zip(steps, inds)))\n",
    "\n",
    "    cut = np.argmax(np.array(steps)>cutoff)\n",
    "    steps = steps[cut:]\n",
    "    inds = inds[cut:]\n",
    "    \n",
    "    vals = r_scores.loc[list(inds)]\n",
    "    name = \"Pythia \" + size\n",
    "    \n",
    "    # Add each component as a separate subplot in its own row\n",
    "    for i in range(n_components):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=steps, y=vals.loc[:, i], mode='lines', line=dict(color=colors[size]),\n",
    "                       name=name, showlegend=i==0),\n",
    "            row=i+1, col=1,\n",
    "        )\n",
    "\n",
    "for i in range(n_components):\n",
    "    for cname in compares:\n",
    "        v = ref_scores.loc[cname][i]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=[steps[0], steps[-1]], y=[v, v], mode='lines', line=dict(color=ccols[cname]),  \n",
    "                       name=cname, showlegend=i==0),\n",
    "            row=i+1, col=1,\n",
    "        )\n",
    "    \n",
    "# Update the layout with appropriate height based on number of subplots\n",
    "fig.update_layout(\n",
    "    height=250 * n_components,  # 250px per subplot\n",
    "    width=900,\n",
    "    showlegend=False,\n",
    "    margin=dict(l=50, r=50, t=50, b=50)\n",
    ")\n",
    "\n",
    "# Update y-axis titles with component names\n",
    "for i in range(n_components):\n",
    "    fig.update_yaxes(title_text=\"Scaled Model Score\", row=i+1, col=1)  # range=[ymin, 2], \n",
    "    fig.update_xaxes(type=\"log\", row=i+1, col=1)\n",
    "    \n",
    "# Update x-axis title (only needed for bottom subplot)\n",
    "fig.update_xaxes(title_text=\"Steps\", row=n_components, col=1)\n",
    "fig.update_layout(\n",
    "    width=1000,\n",
    "    height=2000,\n",
    "    showlegend=True\n",
    ")\n",
    "# fig.update_layout\n",
    "fig.write_image(\"/home/areid/newplots/traces.png\", scale=2)\n",
    "#fig.write_image(\"/home/areid/traces.png\", scale=2)\n",
    "fig.write_html(\"/home/areid/traces.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b5d427-e66d-4c4f-a748-0e67ecba9fc1",
   "metadata": {},
   "source": [
    "Copyright (c) Gradient Institute and Timaeus.\n",
    "\n",
    "Licensed under the Apache 2.0 License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
