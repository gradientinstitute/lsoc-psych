{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d850db20-4c05-4faf-8f88-c34e55344759",
   "metadata": {},
   "source": [
    "# Pythia's Helm-lite Evals against Burnell's Dataset\n",
    "\n",
    "Here we analyse custom helm lite evals we collected against the factors we found in the burnell data.\n",
    "\n",
    "The evals are preliminary because:\n",
    "* low coverage of the evals we wanted\n",
    "* high levels of noise due to reduced (n=100 sampling\n",
    "\n",
    "Prelim analysis suggests this data supports 2 latent factors of similar interpretation to earlier analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9314f016-8a9b-45f8-b472-3ecfa9984589",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Local files\n",
    "from lsoc.factor import factor, selection, vis, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52eb256-4582-4929-a732-70d02bfce6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/RyanBurnell/revealing-LLM-capabilities/refs/heads/main/helm_data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df.set_index('Model', inplace=True)\n",
    "meta = df.iloc[:4]\n",
    "df = df.iloc[4:].astype(float).copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5115abec-42c7-411f-8637-79bd9fd677bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is one missing value in the whole matrix\n",
    "missing_per_row = df.isna().sum(axis=1)\n",
    "df = df[missing_per_row <= 5].copy()\n",
    "missing_per_col = df.isna().sum()\n",
    "cols_to_drop = df.columns[missing_per_col > 5]\n",
    "df.drop(columns=cols_to_drop, inplace=True)\n",
    "disqualified_tasks = [\n",
    "    \"MS_MARCO_(regular)_RR@10\",\n",
    "    \"MS_MARCO_(TREC)_NDCG@10\",\n",
    "    #\"NaturalQuestions_(open-book)_F1\",\n",
    "    \"MATH_(chain-of-thoughts)_Equivalent_(chain_of_thought)\",\n",
    "    \"Data_imputation_EM\",\n",
    "    \"Entity_matching_EM\"\n",
    "]\n",
    "if \"Entity_matching_EM\" in df.columns:\n",
    "    df = df.drop(columns=disqualified_tasks)\n",
    "# impute missing data\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(random_state=0)\n",
    "imputed = pd.DataFrame(imp.fit_transform(df), columns=df.columns, index=df.index)\n",
    "\n",
    "assert imputed.isna().sum().sum() == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d75119e-18cd-4759-b549-d8eb3460d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join our 'helm-reduced' dataset with Burnell's selection of features\n",
    "df_pythia = pd.read_csv(data.default_path + \"/evals/pythia_steps.csv\")\n",
    "df_pythia.set_index('Model', inplace=True)\n",
    "\n",
    "common = sorted(set(df.columns) & set(df_pythia.columns))\n",
    "\n",
    "df_pythia = df_pythia[common]\n",
    "imputed = imputed[common]  # the one we actually use\n",
    "df_pythia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f61c35a-9e82-46c5-9efb-34c1339b59cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holdout model selection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(imputed)  # is a numpy array\n",
    "\n",
    "# model\n",
    "model = factor.PCA()  #FA()\n",
    "errs = selection.cross_validate(imputed, model, max_factors=7, n_folds=20, repeats=1)\n",
    "fig = vis.crossval(*errs, method_name=model.name)\n",
    "fig.show()  # answer - 4 or 5 dimensions\n",
    "\n",
    "# Yep... factor analysis says 3 factors - consistent with burnell paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d152c805-ad96-4487-8462-6de9cf590f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get offset working\n",
    "n_components = 2\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "fa_final = FactorAnalyzer(rotation='oblimin', n_factors=n_components)\n",
    "fa_final.fit(X_scaled)\n",
    "\n",
    "#W = fa.fit_transform(imputed)\n",
    "#H = fa.components_\n",
    "H = fa_final.loadings_.T\n",
    "\n",
    "component_names = [f\"PC{i+1}\" for i in range(n_components)]\n",
    "\n",
    "loading_df = pd.DataFrame(\n",
    "    data=H.T,\n",
    "    index=imputed.columns,\n",
    "    columns=component_names,\n",
    ")\n",
    "\n",
    "ld = np.abs(loading_df.values)\n",
    "main_load = ld.argmax(axis=1)\n",
    "order = np.argsort(main_load * 100 - ld.max(axis=1))\n",
    "loading_df = loading_df.iloc[order]\n",
    "\n",
    "# flip = loading_df.max(axis=1) != loading_df.abs().max(axis=1)\n",
    "# loading_df[flip] *= -1\n",
    "\n",
    "fig = vis.heatmap(\n",
    "    loading_df,\n",
    "    title=\"Task Loadings\",\n",
    "    width=6,\n",
    "    height=12,\n",
    "    reversescale=True\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f697c-c751-4d5d-bdcb-f8d7ce807156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "models = sorted(set(v.split(\"/\")[0] for v in df_pythia.index.values))\n",
    "# Create a figure with two subplots stacked vertically\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True, \n",
    "                   vertical_spacing=0.1,\n",
    "                   subplot_titles=('Z1 (Burnell \"reasoning\")', 'Z2 (Burnell \"comprehension\")'))\n",
    "\n",
    "# Set a different color for each model using Plotly's default colors\n",
    "for i, model in enumerate(models):\n",
    "    # Get the model entries\n",
    "    get = [v for v in df_pythia.index.values if model in v]\n",
    "    step = [int(g.split(\"/\")[1]) for g in get]\n",
    "    dfp = df_pythia.loc[get]\n",
    "    \n",
    "    # Transform the data to get scores\n",
    "    scores = fa_final.transform(dfp)  # scores is n x n_components=2\n",
    "    \n",
    "    # Sort by step to ensure lines connect points in the right order\n",
    "    sorted_indices = np.argsort(step)\n",
    "    step_sorted = np.array(step)[sorted_indices]\n",
    "    scores_sorted = scores[sorted_indices]\n",
    "    \n",
    "    # Plot the first component in the top subplot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=step_sorted,\n",
    "            y=scores_sorted[:, 0],\n",
    "            mode='lines+markers',\n",
    "            name=model,\n",
    "            legendgroup=model,\n",
    "            showlegend=True\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Plot the second component in the bottom subplot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=step_sorted,\n",
    "            y=scores_sorted[:, 1],\n",
    "            mode='lines+markers',\n",
    "            name=model,\n",
    "            legendgroup=model,\n",
    "            showlegend=False  # Don't repeat in legend\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title_text=\"Model Scores vs. Training Steps\",\n",
    "    height=800,\n",
    "    width=1000,\n",
    "    # legend=dict(\n",
    "    #     orientation=\"h\",\n",
    "    #     yanchor=\"bottom\",\n",
    "    #     y=1.02,\n",
    "    #     xanchor=\"right\",\n",
    "    #     x=1\n",
    "    # )\n",
    ")\n",
    "\n",
    "# Set log scale for x-axis on both subplots\n",
    "fig.update_xaxes(type=\"log\", title_text=\"Steps\", row=2, col=1)\n",
    "fig.update_xaxes(type=\"log\", row=1, col=1)\n",
    "\n",
    "# Add y-axis titles\n",
    "fig.update_yaxes(title_text=\"Z1 (Burnell's 'reasoning')\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Z2 (Burnell's 'comprehension')\", row=2, col=1)\n",
    "\n",
    "# Add grid for better readability\n",
    "fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')\n",
    "fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77575e73-fb22-44b5-b879-f04aabe20e22",
   "metadata": {},
   "source": [
    "Copyright (c) Gradient Institute and Timaeus. All rights reserved.\n",
    "\n",
    "Licensed under the Apache 2.0 License.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
